Detecting AI-Generated Fraud content
Problem Statement 

Develop a system designed to identify and mitigate fraud generated by GenAI,
including but not limited to:

AI-generated phishing emails

Detect Exposure of any credentials

Verification of attachments of any form (Pharming)

Challenge
The solution must be capable but not limited to AI-written phishing emails Any creds exposed User verification Website phishing tester, all type of spoofing Attachment verify(Pharming) Website cooking Deepfake voice scams targeting bank customers Prompt Injection / Jailbreaking -Countering Model‑Level Attacks (Prompt Injection, Data Poisoning) Sand box to test if a agentic ai model is vulnerable for dataleaks

Technology
LLMs fine tuned for AI-text detection

Transformers (Hugging Face)

Flask/FastAPI

MFCC-based models
Note: Not limited to the above — you are free to use
any open‑source tools as long as they introduce no risk
and send no data outside the environment.

Other Considerations
Identify manipulation of website cookies.

Evaluate websites for phishing and various spoofing possibilities.

Can consider to deploy sandbox environments to assess whether agentic AI models which are externally developed can be assisted on  any vulnerable to data leaks. prompt injection and jailbreaking to counter model-level attacks.

Continuously learn from emerging fraud patterns.

Reduce false positive rates.

Conduct testing on a various form of data

Provide human-readable explanations

Data 
A combination of publicly accessible datasets can be utilized for phishing emails.—Phishing email datasets are available on platforms like Kaggle and Hugging Face.

You may also consider creating synthetic phishing datasets using online large language models (LLMs).

Reference datasets:

Enron email dataset

Design Considerations
Utilize locally hosted LLMs (such as Ollama or HuggingFace) to operate completely offline.

Implement solutions in Python to ensure control, transparency, and security, avoiding ready-made options.

Prioritize data privacy from the outset.

Refrain from storing sensitive raw data.

Retain only anonymized features and remove any personally identifiable information before training or logging.

Build in mechanisms for continuous feedback, allowing human reviewers to identify false positives and update models accordingly.

Incorporate risk tiers or risk scoring systems.

Benefits
Reduced financial losses from AI-driven fraud

Stronger trust in digital communication channels

Safer banking experience

Better regulatory and compliance postur